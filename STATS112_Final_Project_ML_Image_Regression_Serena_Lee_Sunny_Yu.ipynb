{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaHCenjXGSFa"
      },
      "source": [
        "# Machine Learning: Predicting Average Book Ratings Based on Book Covers\n",
        "\n",
        "The goal of the machine learning portion of this project is to predict a book's average rating based on its book cover. Since rating is a quantitative value, we will be using regression models to predict scores.\n",
        "\n",
        "In the data collection portion of this project, we scraped URLs to the book's cover images. In this notebook, we read those images in a 64x64x3 RGB array and flatten it into a 1-D arrays to use for our test and train data.\n",
        "\n",
        "*NB: not all books had valid cover URLs, so the following models could only predict for the 23,975 books that did."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lykq9jKAFXIl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKIGAqLN4aRp",
        "outputId": "2affd881-e204-445b-b42e-780d4e0b37ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = \"/content/drive/MyDrive/Data Science Final Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB1myZhIFMqe"
      },
      "outputs": [],
      "source": [
        "#read in data (Part 1 and Part 2 show how these csv files were created. ML model testing is in section 3)\n",
        "df_books = pd.read_csv(data_dir + \"books_clean.csv\")\n",
        "df_images = pd.read_csv(data_dir + \"book_covers_full.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKZBDqaiOC_7"
      },
      "source": [
        "# Part 1: Transforming image data into a 1-D array\n",
        "\n",
        "To do this, we needed to standardize the size of the book cover images -- we chose to compress all images using billinear interpolation to preserve the key features (color, shape, all aspects of the cover) and stored all the book covers at 64x64 images. We did this because 64x64x3 (=12288 features) was most compatible with the number of observations we had -- larger images (like 128x128x3=49152) would mean our model has more features than training observations, which would not yield good predictions.\n",
        "\n",
        "Moreover, we found that a 64x64 image was clearer than a 32x32, and so was critical to maintain a good level of key distinguishing features between each book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtsbFsxZPP6c"
      },
      "source": [
        "### Reading images from URL & resizing to prepare for ML model\n",
        "1. Define functions to read and resize image\n",
        "2. Determine the optimal size for the images (64x64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt3ntVs8Eek4"
      },
      "outputs": [],
      "source": [
        "image_urls1 = df_books.loc[df_books[\"image_url\"] != \"\", \"image_url\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_EsW9HuyhJy"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "def read_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img_array = np.array(img)\n",
        "    return img_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmXgFMeM2Ngx"
      },
      "outputs": [],
      "source": [
        "def resize_image(image_array, new_size):\n",
        "    \"\"\"\n",
        "    Resize image array to a new size using bilinear interpolation.\n",
        "    \n",
        "    Parameters:\n",
        "    - image_array: numpy array representing the image\n",
        "    - new_size: tuple representing the new size (width, height)\n",
        "    \n",
        "    Returns:\n",
        "    - resized_image_array: numpy array representing the resized image\n",
        "    \"\"\"\n",
        "    # Convert numpy array to PIL Image object\n",
        "    image = Image.fromarray(image_array)\n",
        "    \n",
        "    # Resize image using bilinear interpolation\n",
        "    resized_image = image.resize(new_size, resample=Image.BILINEAR)\n",
        "    \n",
        "    # Convert PIL Image object to numpy array\n",
        "    resized_image_array = np.array(resized_image)\n",
        "    \n",
        "    return resized_image_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8TdjQt2Ph60"
      },
      "source": [
        "# Part 2: Load a DataFrame of image arrays for each book, the book title & average rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js66W5bGWWX5"
      },
      "outputs": [],
      "source": [
        "image_size = (64, 64)\n",
        "\n",
        "image_urls = image_urls1[:12000]\n",
        "\n",
        "# Define a lambda function that reads an image from a URL, resizes it, and flattens it\n",
        "read_resize_flatten_image = lambda url: resize(imread(url), image_size).flatten()\n",
        "\n",
        "# make a list of flattened image arrays with size 12288 and corresponding book indices\n",
        "image_arrays = []\n",
        "book_titles = []\n",
        "for i, url in enumerate(image_urls):\n",
        "    flattened_image = read_resize_flatten_image(url)\n",
        "    if flattened_image.size == 12288:\n",
        "        image_arrays.append(flattened_image)\n",
        "        book_titles.append(df_books[\"title\"][i])\n",
        "\n",
        "# Create a DataFrame with flattened image arrays and book indices\n",
        "df_images = pd.DataFrame(np.vstack(image_arrays))\n",
        "df_images['rating'] = [df_books.iloc[idx]['avg_rating'] for idx in range(len(image_arrays))]\n",
        "df_images['title'] = book_titles\n",
        "\n",
        "df_images.to_csv(data_dir + 'book_covers.csv', index=False)\n",
        "\n",
        "#second half of data -- so that colab does not exceed output size limit\n",
        "\n",
        "split = 24971 - 12000\n",
        "\n",
        "image_urls = image_urls1[split:]\n",
        "\n",
        "# Define a lambda function that reads an image from a URL, resizes it, and flattens it\n",
        "read_resize_flatten_image = lambda url: resize(imread(url), image_size).flatten()\n",
        "\n",
        "# make a list of flattened image arrays with size 12288 and corresponding book indices\n",
        "image_arrays = []\n",
        "book_titles = []\n",
        "for i, url in enumerate(image_urls):\n",
        "    flattened_image = read_resize_flatten_image(url)\n",
        "    if flattened_image.size == 12288:\n",
        "        image_arrays.append(flattened_image)\n",
        "        book_titles.append(df_books[\"title\"][i])\n",
        "\n",
        "# Create a df with flattened image arrays and book indices\n",
        "df_images = pd.DataFrame(np.vstack(image_arrays))\n",
        "df_images['rating'] = [df_books.iloc[idx]['avg_rating'] for idx in range(len(image_arrays))]\n",
        "df_images['title'] = book_titles\n",
        "\n",
        "df_images.to_csv(data_dir + 'add_book_covers.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_covers = \"/content/drive/MyDrive/Data Science Final Project/book_covers.csv\"\n",
        "add_book_covers = \"/content/drive/MyDrive/Data Science Final Project/add_book_covers.csv\"\n",
        "\n",
        "df1 = pd.read_csv(book_covers)\n",
        "df2 = pd.read_csv(add_book_covers)\n",
        "\n",
        "df_images = pd.concat([df1, df2], axis=0)"
      ],
      "metadata": {
        "id": "S18YCRdng5N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_images.to_csv(data_dir + 'book_covers_full.csv', index=False)"
      ],
      "metadata": {
        "id": "70wcm-qpzEVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The number of books with a valid book cover are {len(df_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE69KZ1AhmhK",
        "outputId": "ca95a433-ae5d-48f1-b78f-23316243eabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of books with a valid book cover are 23975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZTV56nNarNg"
      },
      "source": [
        "Now that we have flattened and stacked the image pixel data, we expect to see a dataframe with 12288 (64x64x3) columns for each pixel + 2 more columns for the book title and its rating. \n",
        "\n",
        "To check for this, we call .shape to ensure there are 12,290 columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XzFK09xqoGe",
        "outputId": "e03df88b-d549-4592-ade2-f59831fa29ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23975, 12290)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Model testing"
      ],
      "metadata": {
        "id": "TtENwPfCg0U0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YJM5guaL1bt"
      },
      "source": [
        "# Hyperparameter testing of K-nearest-neighbors model\n",
        "In this section, K-Neighbors Regressor: best K value?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "HjmmMM5UwJkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQlUUZD6bTdW"
      },
      "outputs": [],
      "source": [
        "X_train = df_images.iloc[:,: 12287]\n",
        "y_train = df_images[\"rating\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLptMgVRLSyD"
      },
      "source": [
        "The trends of training and test MSEs follow what we would expect -- that test MSE is always higher than training MSE. We will zoom in on the 150-500 range as that seems to be more promising for a lower test MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Hrl6MDWRBSZu",
        "outputId": "b87fd196-872c-4f0e-a874-7e0925b8bdcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "470    0.116348\n",
            "480    0.116357\n",
            "460    0.116370\n",
            "490    0.116389\n",
            "440    0.116402\n",
            "Name: Test MSE, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ks = range(150, 500, 10)\n",
        "train_MSEs = []\n",
        "test_MSEs = []\n",
        "\n",
        "for k in ks:\n",
        "  model = KNeighborsRegressor(n_neighbors=k)\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  #computing train error\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  train_MSEs.append(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "  test_MSEs.append(-cross_val_score(\n",
        "      model, X_train, y_train,\n",
        "      scoring=\"neg_mean_squared_error\", cv=10).mean())\n",
        "\n",
        "#get MS errors\n",
        "MSEs = pd.DataFrame({\n",
        "\"Training MSE\": train_MSEs,\n",
        "\"Test MSE\": test_MSEs}, index=ks)\n",
        "MSEs.plot.line(legend=True)\n",
        "\n",
        "print(MSEs[\"Test MSE\"].sort_values()[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#which scaling metric is the best\n",
        "\n",
        "X_train = df_images.iloc[:,: 12287]\n",
        "y_train = df_images[\"rating\"]\n",
        "\n",
        "col_transformer = make_column_transformer(\n",
        "    (StandardScaler(), slice(0, 12287))\n",
        ")\n",
        "\n",
        "for metric in ['euclidean', 'manhattan']:\n",
        "  pipeline = make_pipeline(col_transformer, KNeighborsRegressor(n_neighbors=470, metric=metric))\n",
        "\n",
        "  print(metric, -cross_val_score(\n",
        "      pipeline, X_train, y_train,\n",
        "      scoring=\"neg_mean_squared_error\",\n",
        "      cv=10).mean()\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c339b88-cb49-4c7b-9abe-ac3423e639a0",
        "id": "Xj0SMjOXhY1h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "euclidean 0.11302739879961377\n",
            "manhattan 0.11291609145348043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8bF0rEXGF29"
      },
      "source": [
        "##Explore different features\n",
        "### Comparing model trained on image features against non-image features\n",
        "\n",
        "Can we judge a book by its cover? The cover of a book is more than just the image itself: it contains the book title and the author name!\n",
        "\n",
        "In this section, we compare including these different feautres in a regression model. Using KNN, we compare models using only non-image features vs using image features.\n",
        "\n",
        "Having determined the optimal value of k at k=470, we will  compare how the model fares between training only on book cover images versus other features like: author name, title, book description, and first sentence.\n",
        "\n",
        "For this, we will disaggregate the data along genre-lines to better account for differences in genres. We will focus the model on the most common genre in the dataset: Fiction, which comprises 'fiction and literature' and \"general fiction\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_genres = df_books['genre'].explode().value_counts().head(3)\n",
        "print(f\"most common genres:\\n{top_genres}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBIWOSrv5fsd",
        "outputId": "3438f726-e765-4c4c-91e7-da2800d3e8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "most common genres:\n",
            "Fiction and Literature    19960\n",
            "General Fiction            6346\n",
            "Fantasy                    3735\n",
            "Name: genre, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that 'fiction' features prominently across the top 5 most popular genres in the dataset. We will combine 'Fiction & Literature' and \"General Fiction' in order to see a broader range of books. "
      ],
      "metadata": {
        "id": "jQzvzU01eLTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_fiction = pd.concat([pd.read_csv(\"/content/drive/MyDrive/Data Science Final Project/df_Fiction and Literature\"), \n",
        "                        pd.read_csv(\"/content/drive/MyDrive/Data Science Final Project/df_General Fiction\")])\n",
        "\n",
        "df_fiction = df_fiction.drop_duplicates().dropna()\n",
        "\n",
        "print(f\"There are {len(df_fiction)} books in the Fiction category\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b433f8de-1686-4dae-ece8-a60ed4f5d686",
        "id": "5Ey850TChrWX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 14747 books in the Fiction category\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define features\n",
        "cat_vars = ['author', 'publication_year']\n",
        "tfidf_vars = ['title', 'description', 'first_sentence']\n",
        "y_train = df_fiction['avg_rating']"
      ],
      "metadata": {
        "id": "3vty4tTSh0II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessors = [\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), cat_vars),\n",
        "    (TfidfVectorizer(max_features=50), tfidf_vars)\n",
        "]\n",
        "preprocessors[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34989042-c897-4b72-c663-a2122ed4e0f6",
        "id": "i6cn_PPnh3Bg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TfidfVectorizer(max_features=50), ['title', 'description', 'first_sentence'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_transformers = [make_column_transformer((StandardScaler(), [\"number_of_reviews\"]),\n",
        "    remainder=\"drop\" \n",
        "), make_column_transformer(\n",
        "    (StandardScaler(), [\"number_of_reviews\"]),\n",
        "    (TfidfVectorizer(max_features = 100), 'description'),\n",
        "    (TfidfVectorizer(max_features = 100), 'title'),\n",
        "    remainder=\"drop\" \n",
        "), make_column_transformer(\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"),['author']),\n",
        "    (TfidfVectorizer(max_features = 100), 'title'),\n",
        "    remainder=\"drop\"  \n",
        "), make_column_transformer(\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"),['author']),\n",
        "    (TfidfVectorizer(max_features = 100), 'first_sentence'),\n",
        "    (TfidfVectorizer(max_features = 100), 'description'),\n",
        "    (TfidfVectorizer(max_features = 100), 'title'),\n",
        "    remainder=\"drop\"  \n",
        ")]\n",
        "\n",
        "for model_num, column_transformer in enumerate(column_transformers):\n",
        "    pipeline = make_pipeline(\n",
        "        column_transformer,\n",
        "        KNeighborsRegressor(n_neighbors=20)\n",
        "    )\n",
        "    scores = cross_val_score(\n",
        "        pipeline,\n",
        "        X=df_fiction[['title', 'author', 'description', 'publication_year', 'first_sentence', 'number_of_reviews']],\n",
        "        y=df_fiction['avg_rating'], \n",
        "        scoring=\"neg_mean_squared_error\", \n",
        "        cv=20\n",
        "    )\n",
        "    error = -scores.mean()\n",
        "    print(f\"Error of model #{model_num + 1}: {error}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db4sUbiqDqxx",
        "outputId": "0a6d46c6-88b0-48e4-fed4-6b31de68dfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error of model #1: 0.08310826050452651\n",
            "Error of model #2: 0.0789037170645755\n",
            "Error of model #3: 0.08443445922383648\n",
            "Error of model #4: 0.08125552210820897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model_num, column_transformer in enumerate(column_transformers):\n",
        "  print(f\"{model_num + 1}: {column_transformers[model_num]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYmziOpJIPZh",
        "outputId": "9bc79653-9fa7-405b-b06b-9ef833faa79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: ColumnTransformer(transformers=[('standardscaler', StandardScaler(),\n",
            "                                 ['number_of_reviews'])])\n",
            "2: ColumnTransformer(transformers=[('standardscaler', StandardScaler(),\n",
            "                                 ['number_of_reviews']),\n",
            "                                ('tfidfvectorizer-1',\n",
            "                                 TfidfVectorizer(max_features=100),\n",
            "                                 'description'),\n",
            "                                ('tfidfvectorizer-2',\n",
            "                                 TfidfVectorizer(max_features=100), 'title')])\n",
            "3: ColumnTransformer(transformers=[('onehotencoder',\n",
            "                                 OneHotEncoder(handle_unknown='ignore'),\n",
            "                                 ['author']),\n",
            "                                ('tfidfvectorizer',\n",
            "                                 TfidfVectorizer(max_features=100), 'title')])\n",
            "4: ColumnTransformer(transformers=[('onehotencoder',\n",
            "                                 OneHotEncoder(handle_unknown='ignore'),\n",
            "                                 ['author']),\n",
            "                                ('tfidfvectorizer-1',\n",
            "                                 TfidfVectorizer(max_features=100),\n",
            "                                 'first_sentence'),\n",
            "                                ('tfidfvectorizer-2',\n",
            "                                 TfidfVectorizer(max_features=100),\n",
            "                                 'description'),\n",
            "                                ('tfidfvectorizer-3',\n",
            "                                 TfidfVectorizer(max_features=100), 'title')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KEY FINDING: The best performing model used a combination of 'number_of_reviews' and 'description'. Additionally, all of these models outperformed the book cover data (RMSE = 0.11)."
      ],
      "metadata": {
        "id": "crNZRe26ihod"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}